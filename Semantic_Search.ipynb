{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9c7e9d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as nps\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "import pandas as pd\n",
    "from numpy import random\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Layer\n",
    "from tensorflow.keras.layers import Dense,Input\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from datasets import load_dataset\n",
    "from transformers import AutoTokenizer,create_optimizer,TFAutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5474ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset csv (C:/Users/Admin/.cache/huggingface/datasets/csv/default-813752fff6601379/0.0.0/eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e03e3dc3db84a78a9a88dd9c9e161ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('csv', data_files='data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4598a2a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['query', 'product', 'label'],\n",
       "        num_rows: 3000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f960d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': '# 2 pencils not sharpened',\n",
       " 'product': 'Ticonderoga Beginner Pencils, Wood-Cased #2 HB Soft, With Eraser, Yellow, 12-Pack (13308)',\n",
       " 'label': 'exact'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f613f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting label to numbers\n",
    "\n",
    "def get_label(label):\n",
    "    if label=='exact':\n",
    "        return 1.0\n",
    "    elif label=='substitute':\n",
    "        return 0.7\n",
    "    elif label=='complement':\n",
    "        return 0.5\n",
    "    else:\n",
    "        return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ba60406d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_id=\"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ff1c77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Idea is to fine tune the pre-trained model on my data so, will pass in query + product title and label, \n",
    "# hence modify the process a little\n",
    "\n",
    "\n",
    "BATCH_SIZE=128\n",
    "MAX_LENGTH=64\n",
    "\n",
    "def preprocess(dataset):\n",
    "    if dataset['product']==None:\n",
    "        dataset['product']=dataset['query']\n",
    "    \n",
    "    dataset['input_ids_query']=[]\n",
    "    dataset['token_type_ids_query']=[]\n",
    "    dataset['attention_mask_query']=[]\n",
    "\n",
    "    dataset['input_ids_product']=[]\n",
    "    dataset['token_type_ids_product']=[]\n",
    "    dataset['attention_mask_product']=[]\n",
    "\n",
    "    tokenized_output_query=tokenizer(dataset['query'],max_length=MAX_LENGTH,padding='max_length',truncation=True)\n",
    "    tokenized_output_product=tokenizer(dataset['product'],max_length=MAX_LENGTH,padding='max_length',truncation=True)\n",
    "\n",
    "    dataset['input_ids_query'].append(tokenized_output_query['input_ids'])\n",
    "    dataset['token_type_ids_query'].append(tokenized_output_query['token_type_ids'])\n",
    "    dataset['attention_mask_query'].append(tokenized_output_query['attention_mask'])\n",
    "\n",
    "    dataset['input_ids_product'].append(tokenized_output_product['input_ids'])\n",
    "    dataset['token_type_ids_product'].append(tokenized_output_product['token_type_ids'])\n",
    "    dataset['attention_mask_product'].append(tokenized_output_product['attention_mask'])\n",
    "\n",
    "    dataset['label']=get_label(dataset['label'])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f29d46f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Admin\\.cache\\huggingface\\datasets\\csv\\default-813752fff6601379\\0.0.0\\eea64c71ca8b46dd3f537ed218fc9bf495d5707789152eb2764f5c78fa66d59d\\cache-0e7629e05b7100b2.arrow\n"
     ]
    }
   ],
   "source": [
    "prep_dataset=dataset.map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c698dce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'query': ['# 2 pencils not sharpened'],\n",
       " 'product': ['BIC Evolution Cased Pencil, #2 Lead, Gray Barrel, 24-Count (PGEBP241-BLK)'],\n",
       " 'label': [0.7],\n",
       " 'input_ids_query': [[[0,\n",
       "    468,\n",
       "    116,\n",
       "    5551,\n",
       "    13003,\n",
       "    7,\n",
       "    959,\n",
       "    189173,\n",
       "    33,\n",
       "    297,\n",
       "    2,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1]]],\n",
       " 'token_type_ids_query': [[[0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0]]],\n",
       " 'attention_mask_query': [[[1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0]]],\n",
       " 'input_ids_product': [[[0,\n",
       "    335,\n",
       "    16259,\n",
       "    161312,\n",
       "    43731,\n",
       "    71,\n",
       "    4267,\n",
       "    13003,\n",
       "    4,\n",
       "    64947,\n",
       "    165507,\n",
       "    4,\n",
       "    155438,\n",
       "    108634,\n",
       "    141,\n",
       "    4,\n",
       "    25240,\n",
       "    108210,\n",
       "    15,\n",
       "    683,\n",
       "    11679,\n",
       "    56861,\n",
       "    2357,\n",
       "    20268,\n",
       "    38274,\n",
       "    605,\n",
       "    16,\n",
       "    2,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1]]],\n",
       " 'token_type_ids_product': [[[0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0]]],\n",
       " 'attention_mask_product': [[[1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    1,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0,\n",
       "    0]]]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prep_dataset['train'][21:22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0b58d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to tf dataset\n",
    "tf_dataset = prep_dataset[\"train\"].to_tf_dataset(\n",
    "    columns=['input_ids_query', 'token_type_ids_query', 'attention_mask_query','input_ids_product', 'token_type_ids_product', 'attention_mask_product', 'label'],\n",
    "    shuffle=True,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62600359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': <tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
      "array([0. , 0.7, 0. , 0. , 0.7, 0.7, 0.7, 0.7, 0. , 1. , 0.7, 0.7, 0. ,\n",
      "       0.5, 0.7, 0. , 0.5, 0. , 0. , 1. , 0. , 1. , 0.7, 0. , 1. , 0. ,\n",
      "       0.7, 0. , 0. , 0.7, 0.7, 0. , 0.7, 0. , 0.7, 0.5, 0. , 0.7, 1. ,\n",
      "       1. , 0.7, 1. , 1. , 0. , 0. , 0.7, 0. , 1. , 1. , 0.7, 1. , 0. ,\n",
      "       0. , 1. , 0. , 0. , 0.7, 1. , 0. , 0. , 1. , 0.7, 0. , 1. , 0.7,\n",
      "       0. , 0.7, 1. , 0. , 1. , 1. , 1. , 0.7, 1. , 0.7, 0.7, 1. , 1. ,\n",
      "       0. , 1. , 0.7, 0. , 0. , 0.7, 0. , 0.7, 0. , 0. , 0. , 1. , 0.7,\n",
      "       1. , 0. , 0. , 0. , 0.7, 0.7, 0.7, 0.7, 0.7, 0.7, 0. , 0.7, 0. ,\n",
      "       1. , 1. , 1. , 0. , 1. , 1. , 0. , 0. , 0.7, 1. , 0.7, 0.7, 0. ,\n",
      "       0.7, 0. , 0.7, 1. , 0. , 1. , 0.7, 0. , 0. , 0. , 0. ],\n",
      "      dtype=float32)>, 'input_ids_query': <tf.Tensor: shape=(128, 1, 64), dtype=int64, numpy=\n",
      "array([[[    0,  4880,   166, ...,     1,     1,     1]],\n",
      "\n",
      "       [[    0, 81730,  2276, ...,     1,     1,     1]],\n",
      "\n",
      "       [[    0,   997,  1506, ...,     1,     1,     1]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[    0,  4777, 21025, ...,     1,     1,     1]],\n",
      "\n",
      "       [[    0,     6,     5, ...,     1,     1,     1]],\n",
      "\n",
      "       [[    0,     6,  9444, ...,     1,     1,     1]]], dtype=int64)>, 'token_type_ids_query': <tf.Tensor: shape=(128, 1, 64), dtype=int64, numpy=\n",
      "array([[[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]]], dtype=int64)>, 'attention_mask_query': <tf.Tensor: shape=(128, 1, 64), dtype=int64, numpy=\n",
      "array([[[1, 1, 1, ..., 0, 0, 0]],\n",
      "\n",
      "       [[1, 1, 1, ..., 0, 0, 0]],\n",
      "\n",
      "       [[1, 1, 1, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1, 1, 1, ..., 0, 0, 0]],\n",
      "\n",
      "       [[1, 1, 1, ..., 0, 0, 0]],\n",
      "\n",
      "       [[1, 1, 1, ..., 0, 0, 0]]], dtype=int64)>, 'input_ids_product': <tf.Tensor: shape=(128, 1, 64), dtype=int64, numpy=\n",
      "array([[[     0,   8599,    708, ...,      1,      1,      1]],\n",
      "\n",
      "       [[     0, 197106,    478, ...,      1,      1,      1]],\n",
      "\n",
      "       [[     0, 141499,     25, ...,      1,      1,      1]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[     0, 166504,  44207, ...,      1,      1,      1]],\n",
      "\n",
      "       [[     0,  30848,  24955, ...,      1,      1,      1]],\n",
      "\n",
      "       [[     0,  13018,  29294, ...,      1,      1,      1]]],\n",
      "      dtype=int64)>, 'token_type_ids_product': <tf.Tensor: shape=(128, 1, 64), dtype=int64, numpy=\n",
      "array([[[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]],\n",
      "\n",
      "       [[0, 0, 0, ..., 0, 0, 0]]], dtype=int64)>, 'attention_mask_product': <tf.Tensor: shape=(128, 1, 64), dtype=int64, numpy=\n",
      "array([[[1, 1, 1, ..., 0, 0, 0]],\n",
      "\n",
      "       [[1, 1, 1, ..., 0, 0, 0]],\n",
      "\n",
      "       [[1, 1, 1, ..., 0, 0, 0]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[1, 1, 1, ..., 0, 0, 0]],\n",
      "\n",
      "       [[1, 1, 1, ..., 0, 0, 0]],\n",
      "\n",
      "       [[1, 1, 1, ..., 0, 0, 0]]], dtype=int64)>}\n"
     ]
    }
   ],
   "source": [
    "for i in tf_dataset.take(1):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed863948",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All model checkpoint layers were used when initializing TFBertModel.\n",
      "\n",
      "All the layers of TFBertModel were initialized from the model checkpoint at sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  117653760 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 117653760 (448.81 MB)\n",
      "Trainable params: 117653760 (448.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# modelling\n",
    "model = TFAutoModel.from_pretrained(model_id)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaaebf3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# overwriting train step as architecture is in a way that train query + product and use a mean pooling layer to get the\n",
    "\n",
    "class SentenceTransformer(tf.keras.Model):\n",
    "    def __init__(self,model):\n",
    "        super(SentenceTransformer,self).__init__()\n",
    "        self.model=model\n",
    "        self.dense=Dense(1,activation='sigmoid')\n",
    "\n",
    "    def compile(self,optimizer,loss_fn):\n",
    "        super(SentenceTransformer,self).compile()\n",
    "        self.optimizer=optimizer\n",
    "        self.loss_fn=loss_fn\n",
    "        self.loss_metric=tf.keras.metrics.Mean(name='loss')\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [self.loss_metric]\n",
    "\n",
    "    def mean_pooling(self, model_output, attention_mask):\n",
    "        token_embeddings = model_output[0]\n",
    "\n",
    "        # expand to get attention mask the same shape as embeddings \n",
    "        input_mask_expanded = tf.cast(\n",
    "        tf.broadcast_to(tf.expand_dims(attention_mask, -1), tf.shape(token_embeddings)),\n",
    "        tf.float32)\n",
    "        # have padded tokens so in order to make their weightage 0 multiply with attention mask\n",
    "        return tf.math.reduce_sum(token_embeddings * input_mask_expanded, axis=1)/tf.clip_by_value(tf.math.reduce_sum(input_mask_expanded, axis=1), 1e-9, tf.float32.max)\n",
    "\n",
    "    \n",
    "    def train_step(self,train_data):\n",
    "        query={'input_ids':train_data['input_ids_query'][:,0,:],\n",
    "           'token_type_ids':train_data['token_type_ids_query'][:,0,:],\n",
    "           'attention_mask':train_data['attention_mask_query'][:,0,:]}\n",
    "\n",
    "        product={'input_ids':train_data['input_ids_product'][:,0,:],\n",
    "             'token_type_ids':train_data['token_type_ids_product'][:,0,:],\n",
    "             'attention_mask':train_data['attention_mask_product'][:,0,:]}\n",
    "        \n",
    "        labels=train_data['label']\n",
    "\n",
    "        with tf.GradientTape() as recorder:\n",
    "            query_predictions=self.model(query)\n",
    "            pred_query=self.mean_pooling(query_predictions,train_data['attention_mask_query'][:,0,:])\n",
    "\n",
    "            product_predictions=self.model(product)\n",
    "            pred_product=self.mean_pooling(product_predictions,train_data['attention_mask_product'][:,0,:])\n",
    "            \n",
    "            # u,v, |u-v|\n",
    "            pred_concat=tf.concat([pred_query,pred_product,tf.abs(pred_query-pred_product)],axis=-1)\n",
    "\n",
    "            predictions=self.dense(pred_concat)\n",
    "            loss=self.loss_fn(labels,predictions)\n",
    "\n",
    "\n",
    "        partial_derivatives = recorder.gradient(loss,self.model.trainable_weights)\n",
    "        self.optimizer.apply_gradients(zip(partial_derivatives, self.model.trainable_weights))\n",
    "\n",
    "\n",
    "        self.loss_metric.update_state(loss)\n",
    "        return {'loss':self.loss_metric.result(),}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e535348",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"tf_bert_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " bert (TFBertMainLayer)      multiple                  117653760 \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 117653760 (448.81 MB)\n",
      "Trainable params: 117653760 (448.81 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e5d243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stransformer=SentenceTransformer(model)\n",
    "stransformer.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=2e-5,),\n",
    "    loss_fn=tf.keras.losses.BinaryCrossentropy(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4b4bfaa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "24/24 [==============================] - 305s 11s/step - loss: 0.6563\n",
      "Epoch 2/2\n",
      "24/24 [==============================] - 270s 11s/step - loss: 0.5911\n"
     ]
    }
   ],
   "source": [
    "EPOCHS=2\n",
    "history=stransformer.fit(tf_dataset,epochs=EPOCHS,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6163c219",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stransformer.model.save_weights(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "784204a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create embeddings for the product titles and store\n",
    "filepath_catalogue='product_catalogue-v0.3.csv'\n",
    "df_catalogue=pd.read_csv(filepath_catalogue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "969abdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3000, 7)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_catalogue = df_catalogue[:3000]\n",
    "df_catalogue.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "95b5a28c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Wood-Cased #2 HB Pencils, Shuttle Art 600 Pack Sharpened Yellow Pencils with Erasers, Bulk Pack Graphite Pencils for School and Teacher Supplies, Writhing, Drawing and Sketching'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_catalogue['product_title'][10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9745f79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Amazon Basics Woodcased #2 Pencils, Unsharpened, HB Lead - Box of 144, Bulk Box', 'BAZIC Pencil #2 HB Pencils, Latex Free Eraser, Wood Free Yellow Unsharpened Pencils for Exam School Office (12/Pack), 1-Pack']\n"
     ]
    }
   ],
   "source": [
    "product_titles=[str(df_catalogue['product_title'][i]) for i in range(len(df_catalogue))]\n",
    "print(product_titles[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73a56c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7062dff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INFERENCE_BATCH_SIZE=640\n",
    "len(product_titles)//INFERENCE_BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f23c3187",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0]\n",
    "\n",
    "    # expand to get attention mask the same shape as embeddings \n",
    "    input_mask_expanded = tf.cast(\n",
    "    tf.broadcast_to(tf.expand_dims(attention_mask, -1), tf.shape(token_embeddings)),\n",
    "    tf.float32)\n",
    "    # have padded tokens so in order to make their weightage 0 multiply with attention mask\n",
    "    return tf.math.reduce_sum(token_embeddings * input_mask_expanded, axis=1)/tf.clip_by_value(tf.math.reduce_sum(input_mask_expanded, axis=1), 1e-9, tf.float32.max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "595893fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "# getting embeddings for batches, 4 times pass the full data, 640 batch\n",
    "for i in range(len(product_titles)//INFERENCE_BATCH_SIZE):\n",
    "    tokenized_output=tokenizer(\n",
    "      product_titles[INFERENCE_BATCH_SIZE*i:INFERENCE_BATCH_SIZE*(i+1)],max_length=MAX_LENGTH,padding='max_length',truncation=True,return_tensors=\"tf\")\n",
    "    model_output=model(tokenized_output)\n",
    "    embedding=mean_pooling(model_output,tokenized_output['attention_mask'])\n",
    "    embeddings.append(embedding)\n",
    "    if i%100==0:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bc98708",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(640, 384), dtype=float32, numpy=\n",
       " array([[-0.29282224, -0.07676274, -0.3253273 , ...,  0.26357576,\n",
       "         -0.10390438,  0.2429624 ],\n",
       "        [-0.4563171 ,  0.22972861, -0.13598211, ...,  0.35998857,\n",
       "          0.04396171,  0.2383835 ],\n",
       "        [-0.06812565, -0.02659825, -0.0476185 , ...,  0.4345699 ,\n",
       "         -0.03786996,  0.18956815],\n",
       "        ...,\n",
       "        [-0.37099892,  0.47778252,  0.36435744, ..., -0.18578033,\n",
       "         -0.16245577, -0.17742285],\n",
       "        [-0.3159326 ,  0.24955328,  0.39163116, ..., -0.17924504,\n",
       "         -0.15031905, -0.15297084],\n",
       "        [-0.35707855,  0.2573044 ,  0.26153773, ..., -0.39928892,\n",
       "         -0.24573238,  0.09266718]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(640, 384), dtype=float32, numpy=\n",
       " array([[-0.11752909,  0.34652114,  0.16854785, ..., -0.22907712,\n",
       "         -0.1429412 ,  0.02594221],\n",
       "        [ 0.15281056,  0.29636747,  0.1012983 , ..., -0.21139735,\n",
       "         -0.16036694, -0.20210999],\n",
       "        [-0.29285634,  0.06421579,  0.2307576 , ..., -0.5171073 ,\n",
       "         -0.08550608, -0.02067287],\n",
       "        ...,\n",
       "        [ 0.14185517,  0.3517916 , -0.11695421, ..., -0.04557482,\n",
       "         -0.33794066,  0.22499053],\n",
       "        [ 0.20282745,  0.2355953 , -0.16496867, ..., -0.24798974,\n",
       "         -0.3215802 ,  0.1923268 ],\n",
       "        [-0.20413093,  0.3623071 ,  0.00786837, ..., -0.11132483,\n",
       "         -0.32930377,  0.04816148]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(640, 384), dtype=float32, numpy=\n",
       " array([[ 0.00888436,  0.3081312 ,  0.04622836, ..., -0.09336264,\n",
       "         -0.39531842,  0.089023  ],\n",
       "        [-0.06666981,  0.35087836,  0.08104784, ..., -0.05549014,\n",
       "         -0.3993059 ,  0.0141271 ],\n",
       "        [-0.198467  ,  0.3617839 ,  0.00581107, ..., -0.11972152,\n",
       "         -0.3302294 ,  0.04789973],\n",
       "        ...,\n",
       "        [ 0.12682645,  0.42697176,  0.19146428, ..., -0.09487445,\n",
       "          0.08574797,  0.41861174],\n",
       "        [ 0.03520904,  0.15796201, -0.09573112, ..., -0.49925715,\n",
       "         -0.14669828,  0.31766802],\n",
       "        [-0.02453222,  0.47316974,  0.03084761, ..., -0.12952936,\n",
       "         -0.5927288 ,  0.5123184 ]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(640, 384), dtype=float32, numpy=\n",
       " array([[ 0.23949271,  0.22821906, -0.11315139, ..., -0.14999714,\n",
       "         -0.6854484 ,  0.12485051],\n",
       "        [ 0.29187217,  0.2594017 , -0.09943435, ..., -0.12138862,\n",
       "         -0.55601287,  0.02658916],\n",
       "        [ 0.08965433,  0.13782968,  0.04188358, ..., -0.16864008,\n",
       "         -0.07696849,  0.233375  ],\n",
       "        ...,\n",
       "        [ 0.09357785,  0.2637958 , -0.24179405, ..., -0.08297182,\n",
       "         -0.19559446,  0.3889145 ],\n",
       "        [ 0.14240535,  0.3713279 , -0.23253413, ..., -0.13252036,\n",
       "         -0.04755632,  0.36573523],\n",
       "        [ 0.18812525,  0.0484647 , -0.1387825 , ..., -0.22757068,\n",
       "         -0.20017435,  0.19725142]], dtype=float32)>]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "984afb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the embeddings\n",
    "#np.savez_compressed('embeddings.npz', embeddings)\n",
    "#np.savez_compressed('product_titles.npz',product_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d15402f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use embeddings\n",
    "import numpy as np\n",
    "loaded_embedding=np.load('embeddings.npz')\n",
    "loaded_embedding_array=np.array(loaded_embedding['arr_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ad979df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_titles=np.load('product_titles.npz')\n",
    "loaded_titles_array=np.array(loaded_titles['arr_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c8e8b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 640, 384)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_embedding_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3dfcbc20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2560, 384)\n"
     ]
    }
   ],
   "source": [
    "loaded_embedding_array=loaded_embedding_array.reshape(-1,loaded_embedding_array.shape[2])\n",
    "print(loaded_embedding_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea1fc761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fe8a81a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 384)\n"
     ]
    }
   ],
   "source": [
    "# simulate a single user input\n",
    "inputs = tokenizer([\"Keyboard\"],max_length=MAX_LENGTH,padding='max_length',truncation=True,return_tensors=\"tf\")\n",
    "\n",
    "logits = model(**inputs)\n",
    "out_embedding=mean_pooling(logits,inputs['attention_mask'])\n",
    "print(out_embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "77cbebcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2560, 1)\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity - a,b dot product\n",
    "u_dot_v=np.matmul(loaded_embedding_array,(np.array(out_embedding).T))\n",
    "print(u_dot_v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8490550",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2560,)\n",
      "[4.968757  4.7849097 4.9656568 ... 4.640017  4.803453  4.5058026]\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity - norm of a\n",
    "u_magnitude=np.sqrt(np.sum(loaded_embedding_array*loaded_embedding_array,axis=-1))\n",
    "print(u_magnitude.shape)\n",
    "print(u_magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1b6662f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n",
      "[6.89353]\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity - norm of a\n",
    "v_magnitude=np.sqrt(np.sum(out_embedding*out_embedding,axis=-1))\n",
    "print(v_magnitude.shape)\n",
    "print(v_magnitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8fa0f63e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.22148265 0.25732487 0.21718223 ... 0.10515758 0.08786255 0.10089629]]\n"
     ]
    }
   ],
   "source": [
    "# cosine similarity\n",
    "cosine_similarity=u_dot_v.T/(u_magnitude*v_magnitude)\n",
    "print(cosine_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ed9ad82c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1880 2259  356 ... 1625 1986  107]]\n"
     ]
    }
   ],
   "source": [
    "# sorting to get index of \n",
    "sorted_indices=np.argsort(cosine_similarity,axis=-1)\n",
    "print(sorted_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7a4ace4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['CHOORO Piano Keyboard Pendant Keychain Piano Zipper Pull Music Jewelry Gift for Pianist/Piano Teacher/Music Lovers (Necklace)']\n",
      "1 ['Wise 8WD12 Aluminum Offset Piano Hinge, 11\"']\n",
      "2 ['M SANMERSEN Kids Piano Mat, 39.5\" X 14\" Musical Mat Keyboard Music Mat with 8 Instrument Sounds Touch Play Dancing Mat Gift Toys for Boys Girls']\n"
     ]
    }
   ],
   "source": [
    "# get the last value in the sorted indices and map with title\n",
    "for i in range(3):\n",
    "    print(i,loaded_titles_array[sorted_indices[:,len(sorted_indices[0])-i-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb3f109",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
